{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doc2vec_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limestonestreams/thesis/blob/master/doc2vec_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOwqC5SniALz",
        "colab_type": "text"
      },
      "source": [
        "Setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OkLIHy_iCAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first attempt at keras\n",
        "\n",
        "# keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# doc2vec\n",
        "#   gensim modules\n",
        "from gensim import utils\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "# numpy\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfl5X7EuiG5I",
        "colab_type": "text"
      },
      "source": [
        "Importing the data from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbFkzen-iKiW",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "# get doc2vec numpy vectors\n",
        "url = 'https://github.com/limestonestreams/thesis/blob/master/doc2vec_np_arrays.npz?raw=true'\n",
        "\n",
        "path = tf.keras.utils.get_file('doc2vec_np_arrays.npz', url)\n",
        "with np.load(path) as d2v_np:\n",
        "  train_arrays = d2v_np['train_arrays']\n",
        "  train_labels = d2v_np['train_labels']\n",
        "  test_arrays = d2v_np['test_arrays']\n",
        "  test_labels = d2v_np['test_labels']\n",
        "\n",
        "print(train_arrays.shape[1]) #number of features (shape of each sample), which feeds into the first layer's input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXTthriiOnX",
        "colab_type": "text"
      },
      "source": [
        "Define keras model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqigmwbCiXuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Sequential model with 3 layers\n",
        "# from https://stackoverflow.com/questions/50564928/how-to-use-sentence-vectors-from-doc2vec-in-keras-sequntial-model-for-sentence-s\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation = 'relu', input_shape = (100,))) #using rectified linear unit (ReLU) activation for hidden layers is most common\n",
        "#model.add(Dense(32, activation = 'relu'))\n",
        "#model.add(Dense(16, activation = 'relu'))\n",
        "#model.add(Dense(8, activation = 'relu'))\n",
        "#model.add(Dense(4, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid')) #use sigmoid activation for the final layer in a binary classification problem (softmax for a multi-class classification problem)\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy']) #binary crossentrophy loss is used for binary classification problems\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_arrays, train_labels, batch_size = 10, epochs = 60, validation_data = (test_arrays, test_labels), verbose = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSo2__8gicVQ",
        "colab_type": "text"
      },
      "source": [
        "Evaluate model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo44YE6bid5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from https://www.tensorflow.org/guide/keras/train_and_evaluate/\n",
        "print(\"Evaluating on test data:\")\n",
        "results_test = model.evaluate(test_arrays, test_labels, batch_size = 128)\n",
        "print(\"test loss, test accuracy:\", results_test)\n",
        "\n",
        "# and for training set\n",
        "print(\"Evaluating on training data:\")\n",
        "results_train = model.evaluate(train_arrays, train_labels, batch_size = 128)\n",
        "print(\"train loss, train accuracy:\", results_train)\n",
        "\n",
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred_labels = model.predict_classes(test_arrays)\n",
        "conf_matrix = confusion_matrix(test_labels, pred_labels)\n",
        "print(conf_matrix)\n",
        "\n",
        "# loss visualisation function from https://realpython.com/python-keras-text-classification/\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "#for key in history.history.keys():\n",
        "#    print(key)\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}